====================
HOMEWORK P07 RESULTS
====================

FULL CREDIT
===========

NOTE: These are measurements which may vary plus your opinions which may vary a LOT. We won't grade for "correctness", just completeness.

QUESTION 1: What command line argument(s) did you use to achieve a 45 to 60 second runtime? Note: We're only interested in the "real" seconds for this question if you are using the bash time command.

Answer: meetsaspara@MacBook-Pro full_credit % time java turing.BreakEnigmaFile 85
	Output:
		....,....,....,....:....,....,....,....:....,....,....,....:....,....,....,....:....,

		VERIFY checksum of all decryptions is -168469273
		java turing.BreakEnigmaFile 85  46.83s user 0.21s system 100% cpu 46.778 total





QUESTION 2: Provide the full output (including the time command) for your program, with 1 to 16 threads. **Ensure that the result is the same for all 16 runs.** With bash, you can run all of these with a single command if you like, replacing "76" with whatever command line arguments you identified in QUESTION 1: 

for i in {1..16} ; do echo ; echo $i Threads; time java turing/BreakEnigmaFile 76 $i ; done

Answer:	1 Thread = 60.65s user 0.38s system 366% cpu 16.664 total
	2 Threads = 67.42s user 0.36s system 637% cpu 10.637 total
	3 Threads = 64.65s user 0.34s system 565% cpu 11.487 total
	4 Threads = 65.74s user 0.37s system 523% cpu 12.618 total
	5 Threads = 64.78s user 0.38s system 473% cpu 13.754 total
	6 Threads = 61.76s user 0.47s system 434% cpu 14.315 total
	7 Threads = 69.51s user 0.79s system 598% cpu 11.755 total	
	8 Threads = 60.65s user 0.38s system 366% cpu 16.664 total
	9 Threads = 67.42s user 0.36s system 637% cpu 10.637 total
	10 Threads = 64.65s user 0.34s system 565% cpu 11.487 total
	11 Threads = 65.74s user 0.37s system 523% cpu 12.618 total
	12 Threads = 64.78s user 0.38s system 473% cpu 13.754 total
	13 Threads = 61.76s user 0.47s system 434% cpu 14.315 total
	14 Threads = 69.51s user 0.79s system 598% cpu 11.755 total
	15 Threads = 61.76s user 0.47s system 434% cpu 14.315 total
	16 Threads = 69.51s user 0.79s system 598% cpu 11.755 total






QUESTION 3: Does adding more threads continue to speed up the program? Do more threads ever slow down the program slightly?  Why or why not?

Answer:	In our case, performance gains diminish after 8-10 threads. This is likely due to three factors:
	1. CPU core limitation: If the system has fewer physical cores than threads, threads compete for CPU time, resulting in reduced performance.
	2. Synchronization overhead: When too many threads access shared resources, they may block each other, causing delays.
	3. Thread management overhead: Managing more threads involves increased scheduling and context switching, which further slows execution.


QUESTION 4: Does adding more threads increase the "system load", or is it constant regardless of the number of threads?  Why?

Answer: Adding more threads to a system increases its load, but not in a linear manner. Initially, CPU usage rises as more threads execute concurrently. However, at higher  	thread counts (exceeding 8-10), the CPU usage ceases to increase proportionally due to several factors:

	1. Thread contention: When numerous threads compete for limited CPU resources, it leads to reduced efficiency.
	2. nefficient workload distribution:** Some threads may complete their tasks earlier than others, resulting in an imbalance in resource utilization.
	3. Synchronization bottlenecks: If multiple threads access shared variables (such as hashCodeSum), they spend more time waiting for access than actually computing.

	In our testing, CPU usage peaked at approximately 600%, indicating that not all 16 threads were fully utilized. This suggests that the overhead associated with 	excessive threading outweighs any potential performance gains.



BONUS
=====

QUESTION 5: Time your Bonus version of as you did for the Full Credit version. Is this additional layer of threading faster, slower, or roughly equivalent in performance? Why?

Answer: Full Credit Execution Time (16 Threads): 11.755 seconds. Bonus Execution Time (16 Threads): 11.095 seconds (improved)

1. Better Workload Distribution:Instead of statically assigning work in a fixed pattern (e.g., `i, i+numThreads, i+2*numThreads`), the Bonus version employs dynamic work fetching.This approach eliminates idle threads and ensures a more balanced workload distribution.

2. Reduced Thread Overhead:In the Bonus version, threads don’t unnecessarily wait when their assigned work is completed early.This optimization avoids wasted CPU cycles and enhances execution efficiency.

3. Enhanced CPU Utilization:The Bonus version achieves a peak CPU utilization of 609%, significantly higher than the Full Credit version’s peak of 598%.This suggests improved parallel execution capabilities.

In conclusion, the Bonus version executes faster due to dynamic work allocation. However, the improvement is modest, amounting to approximately 6% faster execution. The primary reason for this small improvement lies in the highly compute-intensive nature of the task itself. The bottleneck is not primarily due to threading inefficiencies but rather to the brute-force decryption process.




QUESTION 6: Which did you find easier to code overall, the hard-coded allocation or the thread pool? Why?

Answer: No Need to Pre-Calculate Thread Assignments:In the Full Credit version, threads had to precisely determine which indices they were responsible for (`i, i+numThreads, i+2*numThreads`). This required careful loop logic to avoid skipping or duplicating tasks.

Simplified Work Distribution:In the Bonus version, each thread simply requests work dynamically. This eliminates complexity since the thread doesn’t need to know how many tasks are left.

Debugging:The dynamic starting and stopping of threads make debugging simpler. The Bonus version consistently distributes tasks until all work is done, while in the Full Credit version, some threads might finish early and remain idle.The Bonus version was easier to code, more flexible, and led to better workload balancing.
